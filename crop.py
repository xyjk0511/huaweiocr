import os
import sys
import json
import cv2
import shutil
import numpy as np
from inference_sdk import InferenceHTTPClient

def load_dotenv(path=".env"):
    if not os.path.exists(path):
        return
    try:
        with open(path, "r", encoding="utf-8") as f:
            for raw in f:
                line = raw.strip()
                if not line or line.startswith("#") or "=" not in line:
                    continue
                key, val = line.split("=", 1)
                key = key.strip()
                val = val.strip().strip('"').strip("'")
                if key and key not in os.environ:
                    os.environ[key] = val
    except Exception:
        pass

# ==================== åŸºç¡€é…ç½® ====================
load_dotenv()
API_KEY = os.environ.get("API_KEY", "")
if not API_KEY:
    raise RuntimeError("API_KEY is missing. Set it in .env or environment variables.")

# æ¨¡å‹1ï¼šè£å‰ªå¤§æ ‡ç­¾ï¼ˆä½ åŸæ¥ç±»ä¼¼ "huawei-2ha7t/7"ï¼‰
MODEL1_ID = "huawei-2ha7t/7"
MODEL1_LABEL_CLASS = "huawei_label"   # å¦‚æœä½ çš„å¤§æ ‡ç­¾ç±»åä¸æ˜¯è¿™ä¸ªï¼Œå°±æ”¹æˆä½ Roboflowé‡Œçš„classå

# æ¨¡å‹2ï¼šè£å‰ªå­—æ®µï¼ˆä½ è¯´çš„æ–°æ¨¡å‹ sn_model / sn_model 2ï¼‰
# å¸¸è§å†™æ³•å°±æ˜¯ "sn_model/2"ï¼›å¦‚æœRoboflowæ˜¾ç¤ºçš„æ˜¯ "sn-model-xxxx/2"ï¼Œå°±å†™é‚£ä¸ª
MODEL2_ID = ("sn_model/6")
MODEL2_MODEL_CLASS = "model"          # ä½ çš„å­—æ®µç±»å
MODEL2_SN_CLASS = "sn"                # ä½ çš„å­—æ®µç±»å

INPUT_DIR = "new_images"
STAGE1_DIR = "stage1_labels"          # æ‰€æœ‰å°å›¾éƒ½æ”¾è¿™é‡Œï¼ˆæ‰å¹³æ–‡ä»¶å¤¹ï¼‰
STAGE2_DIR = "stage2_fields"
OUT_MODEL_DIR = os.path.join(STAGE2_DIR, "model")
OUT_SN_DIR = os.path.join(STAGE2_DIR, "sn")
MANIFEST_PATH = os.path.join(STAGE2_DIR, "manifest.jsonl")
FAILED_DIR = os.path.join(STAGE2_DIR, "failed")

# è£å‰ª/è¿‡æ»¤å‚æ•°ï¼ˆæŒ‰éœ€å¾®è°ƒï¼‰
MIN_CONF_1 = 0.50
MIN_SIZE_1 = 300
PADDING_1 = 0.15
NMS_1 = 0.30

# Stage2 åˆ†ç±»é˜ˆå€¼ï¼ˆæ¨èï¼‰
MIN_CONF_MODEL = 0.40
MIN_CONF_SN    = 0.15   # é•¿æœŸç¨³å®šé˜ˆå€¼

# Model å°ºå¯¸è¿‡æ»¤ (å®½>=120, é«˜>=18)
MIN_W_MODEL = 120
MIN_H_MODEL = 18

MIN_SIZE_SN    = 60     # 60 èƒ½è¦†ç›–å¤§éƒ¨åˆ†çª„æ¡ sn

PADDING_2_MODEL = 0.10
PADDING_2_SN    = 0.15  # sn å¸¦æ¡ç ï¼Œè¾¹ç¼˜ç•™å¤šä¸€ç‚¹æ›´ç¨³
NMS_2 = 0.30

# ==================== ç¯å¢ƒç»†èŠ‚ï¼šWindowsä¸­æ–‡è·¯å¾„ ====================
try:
    if sys.platform.startswith("win"):
        sys.stdout.reconfigure(encoding="utf-8")
except Exception:
    pass

def ensure_dirs():
    # æ¯æ¬¡å¯åŠ¨æ—¶æ¸…ç©ºç›®å½•
    if os.path.exists(STAGE1_DIR):
        shutil.rmtree(STAGE1_DIR)
    if os.path.exists(STAGE2_DIR):
        shutil.rmtree(STAGE2_DIR)

    os.makedirs(INPUT_DIR, exist_ok=True)
    os.makedirs(STAGE1_DIR, exist_ok=True)
    os.makedirs(OUT_MODEL_DIR, exist_ok=True)
    os.makedirs(OUT_SN_DIR, exist_ok=True)
    os.makedirs(FAILED_DIR, exist_ok=True)
    os.makedirs(os.path.dirname(MANIFEST_PATH), exist_ok=True)

def read_image(path):
    data = np.fromfile(path, dtype=np.uint8)
    img = cv2.imdecode(data, cv2.IMREAD_COLOR)
    return img

def save_png(path, bgr):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    ok, buf = cv2.imencode(".png", bgr)
    if ok:
        buf.tofile(path)
        return True
    return False

def pred_class(p):
    return p.get("class") or p.get("class_name") or ""

def to_xywh_topleft(p):
    x = float(p["x"]); y = float(p["y"])
    w = float(p["width"]); h = float(p["height"])
    x1 = int(x - w/2); y1 = int(y - h/2)
    return x1, y1, int(w), int(h)

def crop_from_pred(img, p, pad_ratio):
    H, W = img.shape[:2]
    x = float(p["x"]); y = float(p["y"])
    w = float(p["width"]); h = float(p["height"])
    pad_w = w * pad_ratio
    pad_h = h * pad_ratio

    x1 = int(x - w/2 - pad_w)
    y1 = int(y - h/2 - pad_h)
    x2 = int(x + w/2 + pad_w)
    y2 = int(y + h/2 + pad_h)

    x1 = max(0, x1); y1 = max(0, y1)
    x2 = min(W, x2); y2 = min(H, y2)
    if x2 <= x1 or y2 <= y1:
        return None
    crop = img[y1:y2, x1:x2]
    return crop if crop.size else None

def nms(preds, min_conf, nms_thresh):
    boxes, confs, kept = [], [], []
    for p in preds:
        if not isinstance(p, dict):
            continue
        if "x" not in p:
            continue
        conf = float(p.get("confidence", 1.0))
        if conf < min_conf:
            continue
        x1, y1, w, h = to_xywh_topleft(p)
        boxes.append([x1, y1, w, h])
        confs.append(conf)
        kept.append(p)

    if not boxes:
        return []
    idxs = cv2.dnn.NMSBoxes(boxes, confs, min_conf, nms_thresh)
    if idxs is None or len(idxs) == 0:
        return []
    idxs = idxs.flatten().tolist() if hasattr(idxs, "flatten") else list(idxs)
    return [kept[i] for i in idxs]

def list_images(folder):
    exts = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}
    return [os.path.join(folder, f) for f in os.listdir(folder)
            if os.path.splitext(f)[1].lower() in exts]

# ==================== Roboflow Client ====================
client = InferenceHTTPClient(api_url="https://detect.roboflow.com", api_key=API_KEY)

# âš ï¸ ä¿®æ­£ï¼šTMP_DIR å¿…é¡»åœ¨ ensure_dirs ä¹‹ååˆ›å»ºï¼Œæˆ–è€…åœ¨ infer_with_resize é‡Œç¡®ä¿å­˜åœ¨
# å› ä¸º ensure_dirs ä¼šåˆ é™¤ STAGE1_DIRï¼Œå¯¼è‡´ TMP_DIR ä¹Ÿä¸å­˜åœ¨äº†
TMP_DIR = os.path.join(STAGE1_DIR, "_tmp_infer")

def _write_tmp_jpg(bgr, out_path, quality=85):
    # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    ok, buf = cv2.imencode(".jpg", bgr, [int(cv2.IMWRITE_JPEG_QUALITY), int(quality)])
    if ok:
        buf.tofile(out_path)
        return True
    return False

def infer_with_resize(original_img_bgr, original_img_path, model_id, max_side=1600):
    """
    ç›®çš„ï¼šé¿å… 413ï¼ŒæŠŠå›¾ç¼©æ”¾å‹ç¼©åå† inferã€‚
    è¿”å›ï¼špredictionsï¼ˆåæ ‡å·²æ˜ å°„å› original_img_bgr çš„åƒç´ åæ ‡ç³»ï¼‰
    """
    H, W = original_img_bgr.shape[:2]
    longest = max(H, W)

    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆåªç¼©å°ä¸æ”¾å¤§ï¼‰
    scale = 1.0
    if longest > max_side:
        scale = max_side / float(longest)

    # ç”Ÿæˆä¸´æ—¶å›¾
    if scale < 1.0:
        resized = cv2.resize(original_img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)
    else:
        resized = original_img_bgr

    base = os.path.splitext(os.path.basename(original_img_path))[0]
    tmp_path = os.path.join(TMP_DIR, f"{base}__infer_tmp.jpg")

    # ä¸¤æ¬¡å°è¯•ï¼šç¬¬ä¸€æ¬¡è´¨é‡85ï¼Œä»413å°±å†é™è´¨é‡+å†ç¼©
    attempts = [
        {"quality": 85, "max_side": max_side},
        {"quality": 70, "max_side": min(max_side, 1200)},
    ]

    last_err = None
    for a in attempts:
        ms = a["max_side"]
        q = a["quality"]

        # é‡æ–°æŒ‰æœ¬è½® max_side è®¡ç®— scale
        scale = 1.0
        if longest > ms:
            scale = ms / float(longest)
        if scale < 1.0:
            resized = cv2.resize(original_img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)
        else:
            resized = original_img_bgr

        _write_tmp_jpg(resized, tmp_path, quality=q)

        try:
            res = client.infer(tmp_path, model_id=model_id)
            preds = (res.get("predictions", []) if isinstance(res, dict) else res) or []

            # åæ ‡ä» resized æ˜ å°„å› originalï¼šé™¤ä»¥ scale
            if scale != 1.0:
                mapped = []
                inv = 1.0 / scale
                for p in preds:
                    if not isinstance(p, dict) or "x" not in p:
                        continue
                    p2 = dict(p)
                    p2["x"] = float(p2["x"]) * inv
                    p2["y"] = float(p2["y"]) * inv
                    p2["width"] = float(p2["width"]) * inv
                    p2["height"] = float(p2["height"]) * inv
                    mapped.append(p2)
                preds = mapped

            return preds

        except Exception as e:
            last_err = e
            # ç»§ç»­ä¸‹ä¸€è½®é™è´¨é‡/é™åˆ†è¾¨ç‡
            continue

    # ä¸¤æ¬¡éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæœ€åä¸€æ¬¡é”™è¯¯
    raise last_err

# ==================== Stage 1ï¼šå¤§å›¾ -> æ ‡ç­¾å°å›¾ ====================
def stage1_crop_labels(img_path):
    img = read_image(img_path)
    if img is None:
        print(f"âŒ è¯»å›¾å¤±è´¥: {img_path}")
        return []

    # ç›´æ¥æ¨ç†ï¼Œä¸åšé¢å¤–è¿‡æ»¤
    preds = infer_with_resize(img, img_path, model_id=MODEL1_ID)

    # åªä¿ç•™å¤§æ ‡ç­¾ç±»åˆ«ï¼ˆè¿™ä¸ªä¿ç•™ï¼Œå¦åˆ™åˆ«çš„ä¹±ä¸ƒå…«ç³Ÿçš„æ¡†ä¹Ÿä¼šè¢«è£å‡ºæ¥ï¼‰
    preds = [p for p in preds if pred_class(p) == MODEL1_LABEL_CLASS]

    # ä¸å†åšå°ºå¯¸è¿‡æ»¤ / ç½®ä¿¡åº¦è¿‡æ»¤ / NMS
    final_preds = preds

    base = os.path.splitext(os.path.basename(img_path))[0]
    out_paths = []

    for i, p in enumerate(final_preds, 1):
        crop = crop_from_pred(img, p, PADDING_1)
        if crop is None:
            continue
        out_name = f"{base}__label_{i}.png"
        out_path = os.path.join(STAGE1_DIR, out_name)
        save_png(out_path, crop)
        out_paths.append(out_path)

    print(f"Stage1: {os.path.basename(img_path)} -> {len(out_paths)} label crops")
    return out_paths

# ==================== Stage 2ï¼šæ ‡ç­¾å°å›¾ -> model/sn å°å— ====================
def stage2_crop_fields(label_img_path):
    img = read_image(label_img_path)
    if img is None:
        return None

    # å†…éƒ¨å‡½æ•°ï¼šåªæŒ‰ç±»åˆ«åˆ†ç»„ï¼Œä¸åšä»»ä½•è¿‡æ»¤
    def parse_preds(raw_preds):
        by_cls = {MODEL2_MODEL_CLASS: [], MODEL2_SN_CLASS: []}
        for p in raw_preds:
            if not isinstance(p, dict):
                continue
            if "x" not in p:
                continue
            c = pred_class(p)
            if c in by_cls:
                by_cls[c].append(p)
        # ä¸åšå°ºå¯¸/ç½®ä¿¡åº¦è¿‡æ»¤ï¼Œä¹Ÿä¸åš NMSï¼Œå…¨éƒ¨ä¿ç•™
        return by_cls[MODEL2_MODEL_CLASS], by_cls[MODEL2_SN_CLASS]

    # Round 1: max_side=1600
    preds1 = infer_with_resize(img, label_img_path, MODEL2_ID, max_side=1600)

    # Debugï¼ˆä¿ç•™ä½ åŸæœ¬çš„è°ƒè¯•é€»è¾‘ï¼‰
    bn = os.path.basename(label_img_path)
    if bn in {"1__label_6.png", "2__label_6.png"} or bn.startswith("2dc0ee5e") or bn.startswith("358d508d"):
        print(f"DEBUG {bn} RAW PREDS (R1):", json.dumps(preds1, ensure_ascii=False)[:2000])

    model_preds, sn_preds = parse_preds(preds1)

    # å¦‚æœæŸä¸€ç±»ä¸ºç©ºï¼Œå†è·‘ä¸€è½®æ›´å¤§ max_sideï¼ˆåªä¸ºäº†å¯èƒ½å¤šæŠ“ä¸€ç‚¹æ¡†ï¼Œä¸åšâ€œåˆè§„åˆ¤æ–­â€ï¼‰
    if not model_preds or not sn_preds:
        preds2 = infer_with_resize(img, label_img_path, MODEL2_ID, max_side=2048)
        combined = (preds1 or []) + (preds2 or [])
        model_preds, sn_preds = parse_preds(combined)

    # åªå–æ¯ä¸€ç±»ç½®ä¿¡åº¦æœ€é«˜çš„é‚£ä¸ªæ¡†
    def best_pred(pred_list):
        if not pred_list:
            return None
        return max(pred_list, key=lambda x: float(x.get("confidence", 1.0)))

    best_model_pred = best_pred(model_preds)
    best_sn_pred = best_pred(sn_preds)

    base = os.path.splitext(os.path.basename(label_img_path))[0]
    out = {
        "label_crop": label_img_path,
        "model_path": None,
        "sn_path": None,
        "model_conf": None,
        "sn_conf": None,
    }

    # å¤„ç† Modelï¼šåªè£å‰ªæœ€é«˜ç½®ä¿¡çš„ä¸€ä¸ª
    if best_model_pred is not None:
        crop_m = crop_from_pred(img, best_model_pred, PADDING_2_MODEL)
        if crop_m is not None:
            mp = os.path.join(OUT_MODEL_DIR, f"{base}__model.png")
            save_png(mp, crop_m)
            out["model_path"] = mp
            out["model_conf"] = float(best_model_pred.get("confidence", 0))

    # å¤„ç† SNï¼šåªè£å‰ªæœ€é«˜ç½®ä¿¡çš„ä¸€ä¸ª
    if best_sn_pred is not None:
        crop_s = crop_from_pred(img, best_sn_pred, PADDING_2_SN)
        if crop_s is not None:
            sp = os.path.join(OUT_SN_DIR, f"{base}__sn.png")
            save_png(sp, crop_s)
            out["sn_path"] = sp
            out["sn_conf"] = float(best_sn_pred.get("confidence", 0))

    # å¦‚æœ model/sn éƒ½æ²¡å‡ºæ¥ï¼ŒæŠŠåŸå°å›¾å¤åˆ¶åˆ° failed æ–¹ä¾¿å›çœ‹
    if not out["model_path"] and not out["sn_path"]:
        fail_path = os.path.join(FAILED_DIR, f"{base}__FAILED.png")
        save_png(fail_path, img)

    return out

def main():
    ensure_dirs()
    
    # é¢å¤–åˆ›å»ºåˆ†ç±»æ–‡ä»¶å¤¹
    MISS_SN_DIR = os.path.join(STAGE2_DIR, "miss_sn")
    MISS_MODEL_DIR = os.path.join(STAGE2_DIR, "miss_model")
    MISS_BOTH_DIR = os.path.join(STAGE2_DIR, "miss_both")
    os.makedirs(MISS_SN_DIR, exist_ok=True)
    os.makedirs(MISS_MODEL_DIR, exist_ok=True)
    os.makedirs(MISS_BOTH_DIR, exist_ok=True)

    imgs = list_images(INPUT_DIR)
    if not imgs:
        print(f"âš ï¸ {INPUT_DIR} æ²¡æœ‰å›¾ç‰‡ï¼ŒæŠŠåŸå§‹å¤§å›¾æ”¾è¿›å»å†è·‘")
        return

    # æ¸…ç©º manifestï¼ˆæ¯æ¬¡è·‘é‡æ–°ç”Ÿæˆï¼‰
    with open(MANIFEST_PATH, "w", encoding="utf-8") as f:
        pass

    # Stage1ï¼šå…¨éƒ¨å¤§å›¾ -> å°å›¾
    all_label_crops = []
    for p in imgs:
        all_label_crops.extend(stage1_crop_labels(p))

    # Stage2ï¼šå…¨éƒ¨å°å›¾ -> model/sn
    ok_any = 0
    ok_both = 0
    with open(MANIFEST_PATH, "a", encoding="utf-8") as f:
        for lp in all_label_crops:
            r = stage2_crop_fields(lp)
            if not r:
                continue
            f.write(json.dumps(r, ensure_ascii=False) + "\n")
            
            has_model = bool(r.get("model_path"))
            has_sn = bool(r.get("sn_path"))
            
            if has_model or has_sn:
                ok_any += 1
            if has_model and has_sn:
                ok_both += 1
                
            # åˆ†ç±»æ‹·è´å¤±è´¥æ ·æœ¬
            if has_model and not has_sn:
                shutil.copy2(lp, os.path.join(MISS_SN_DIR, os.path.basename(lp)))
            elif has_sn and not has_model:
                shutil.copy2(lp, os.path.join(MISS_MODEL_DIR, os.path.basename(lp)))
            elif (not has_sn) and (not has_model):
                shutil.copy2(lp, os.path.join(MISS_BOTH_DIR, os.path.basename(lp)))

    print(f"\nâœ… å®Œæˆï¼šStage1 äº§å‡º {len(all_label_crops)} å¼ å°å›¾")
    print(f"ğŸ“Š ç»Ÿè®¡ï¼šè‡³å°‘æœ‰ä¸€ä¸ªå­—æ®µ {ok_any} å¼ ï¼›ä¸¤ä¸ªå­—æ®µéƒ½æœ‰ {ok_both} å¼ ")
    print(f"ğŸ“„ ç»“æœæ¸…å•ï¼š{MANIFEST_PATH}")
    print(f"ğŸ“‚ å¤±è´¥åˆ†ç±»ï¼š{MISS_SN_DIR} / {MISS_MODEL_DIR}")

if __name__ == "__main__":
    main()
