import os
import json
import re
import sys
import warnings

import paddle
from paddleocr import PaddleOCR
from app_paths import ensure_models_installed

# ================== é…ç½®åŒº ==================
# ä½ çš„ sn å°å›¾ç›®å½•
IMG_DIR = r"C:\Users\55093\PycharmProjects\PythonProject24\stage2_fields\sn"

# è¾“å‡º JSONL æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€å¼ å›¾ç‰‡çš„ç»“æœï¼‰
OUT_JSONL = os.path.join(IMG_DIR, "sn_ocr_results.jsonl")

# ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆä½äºè¿™ä¸ªå°±å½“æˆå™ªå£°ä¸¢æ‰ï¼‰
MIN_SCORE = 0.5

# PaddleOCR è¯­è¨€ï¼š
#   - åªè¯†åˆ«æ•°å­—/å¤§å†™å­—æ¯ä¸ºä¸»ï¼šå»ºè®® lang="en"
#   - å¦‚æœå¯èƒ½æœ‰ä¸­æ–‡ï¼šå¯ä»¥æ”¹æˆ lang="ch"
OCR_LANG = "en"

# æ˜¯å¦ä½¿ç”¨ GPUï¼ˆä½ ç°åœ¨ä¸€èˆ¬æ˜¯ CPUï¼Œå°± Falseï¼‰
USE_GPU = False
# ===========================================


def patch_paddlex_dep_checks():
    """
    In packaged builds, dependency metadata can be missing even if modules exist.
    Patch PaddleX to accept available modules based on importability.
    """
    try:
        import importlib.util
        from paddlex.utils import deps
    except Exception:
        return

    if getattr(deps, "_patched_by_app", False):
        return

    orig_is_dep_available = deps.is_dep_available

    def _module_exists(name):
        try:
            return importlib.util.find_spec(name) is not None
        except Exception:
            return False

    alias_map = {
        "opencv-contrib-python": ["cv2"],
        "opencv-python": ["cv2"],
        "python-bidi": ["bidi"],
        "pyclipper": ["pyclipper"],
    }

    def patched(dep, /, check_version=False):
        try:
            if orig_is_dep_available(dep, check_version=check_version):
                return True
        except Exception:
            pass

        names = list(alias_map.get(dep, []))
        if "-" in dep:
            names.append(dep.replace("-", "_"))

        for name in names:
            if _module_exists(name):
                return True
        return False

    deps.is_dep_available = patched
    deps.require_deps = lambda *args, **kwargs: None
    deps.require_extra = lambda *args, **kwargs: None
    deps._patched_by_app = True


def list_image_files(img_dir):
    """åˆ—å‡ºç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰"""
    exts = {".jpg", ".jpeg", ".png", ".bmp", ".webp", ".tif", ".tiff"}
    files = []
    for name in os.listdir(img_dir):
        ext = os.path.splitext(name)[1].lower()
        if ext in exts:
            files.append(name)
    files.sort()
    return files


def init_ocr():
    """åˆå§‹åŒ– PaddleOCR å¼•æ“ï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰"""
    # å¯é€‰ï¼šå…³æ‰ä¸€äº›æ²¡å¿…è¦çš„ warning
    warnings.filterwarnings("ignore")

    ensure_models_installed()
    patch_paddlex_dep_checks()

    # ä½ ä¹‹å‰æ—¥å¿—é‡Œç”¨è¿‡è¿™ä¸ªç¯å¢ƒå˜é‡ï¼Œè¿™é‡Œé¡ºä¾¿è®¾ä¸€ä¸‹
    os.environ["DISABLE_MODEL_SOURCE_CHECK"] = "True"
    os.environ["PADDLE_PDX_DISABLE_MODEL_SOURCE_CHECK"] = "True"

    device = "gpu" if USE_GPU else "cpu"
    paddle.set_device(device)
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– PaddleOCR å¼•æ“ï¼ˆlang='{}', device='{}'ï¼‰...".format(
        OCR_LANG, device
    ))
    ocr = PaddleOCR(
        use_angle_cls=True,   # è‡ªåŠ¨åˆ¤æ–­æ–‡å­—æ–¹å‘
        lang=OCR_LANG,
    )
    print("âœ… OCR å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    return ocr


def ocr_one_image(ocr, img_path):
    """
    è¯†åˆ«å•å¼ å›¾ç‰‡ï¼Œè¿”å›ï¼š
      - texts: [{'text': str, 'score': float}, ...]
      - concat: æŠŠé«˜ç½®ä¿¡åº¦æ–‡æœ¬æ‹¼èµ·æ¥çš„å­—ç¬¦ä¸²
    """
    result = ocr.ocr(img_path)

    texts = []
    # paddleocr 3.x è¿”å› list[dict]ï¼Œæ—§ç‰ˆæœ¬è¿”å› list[list]
    if result and isinstance(result[0], dict):
        img_result = result[0]
        rec_texts = img_result.get("rec_texts", []) or []
        rec_scores = img_result.get("rec_scores", []) or []
        for text, score in zip(rec_texts, rec_scores):
            texts.append({"text": text, "score": float(score)})
    else:
        # æ—§ç‰ˆç»“æ„ï¼šlist[ img_result ]ï¼Œä¸€å¼ å›¾å¯¹åº”ä¸€ä¸ª img_result
        for img_result in result:
            for line in img_result:
                # line[1] = (text, score)
                text = line[1][0]
                score = float(line[1][1])
                texts.append({"text": text, "score": score})

    # åªä¿ç•™é«˜ç½®ä¿¡åº¦çš„ç‰‡æ®µå†æ‹¼æ¥
    high_conf_texts = [t["text"] for t in texts if t["score"] >= MIN_SCORE]
    concat = "".join(high_conf_texts)

    concat = normalize_sn_text(concat)

    return texts, concat


def normalize_sn_text(text):
    """
    çº æ­£å¸¸è§çš„ SN å­—æ®µè¯†åˆ«é”™è¯¯ã€‚
    è§„åˆ™ï¼šæŠŠ SIN/S1N/SN- ç»Ÿä¸€ä¸º SN:ï¼Œå¹¶å°† ER åä¸€ä½è‹¥æ˜¯æ•°å­— 4/8 çº æˆ A/Bã€‚
    """
    if not text:
        return text

    normalized = text.replace("S1N:", "SN:").replace("SIN:", "SN:").replace("SN-", "SN:")

    # AP162E å¸¸è§æ ¼å¼ï¼š21500871494 + ER[A-C/9] + 4~7ä½æ•°å­—
    # çº é”™ï¼š...71484... -> ...71494...ï¼›ER8/ER4 -> ERB/ERA
    if "21500871484ER" in normalized:
        normalized = normalized.replace("21500871484ER", "21500871494ER")

    normalized = normalized.replace("ER8", "ERB").replace("ER4", "ERA")
    # S380-S8P2T å¸¸è§ SN å‰ç¼€ï¼š4E25A017xxxxï¼Œå¦‚æœè¯†åˆ«æˆ 4E28A017 åˆ™çº æ­£
    if "4E28A017" in normalized:
        normalized = normalized.replace("4E28A017", "4E25A017")
    # å»æ‰é‡å¤çš„ SN å‰ç¼€ï¼Œæ¯”å¦‚ "SN215..." -> "215..."
    normalized = re.sub(r"^SN:?", "", normalized)
    return normalized


def main():
    # å…¼å®¹ Windows æ§åˆ¶å°ä¸­æ–‡è¾“å‡º
    try:
        if sys.platform.startswith("win"):
            sys.stdout.reconfigure(encoding="utf-8")
    except Exception:
        pass

    if not os.path.isdir(IMG_DIR):
        print("âŒ ç›®å½•ä¸å­˜åœ¨ï¼š", IMG_DIR)
        return

    files = list_image_files(IMG_DIR)
    if not files:
        print("âš ï¸ åœ¨ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡ï¼š", IMG_DIR)
        return

    print("ğŸ“‚ å‘ç°å›¾ç‰‡ {} å¼ ï¼Œç›®å½•ï¼š{}".format(len(files), IMG_DIR))

    ocr = init_ocr()

    # æ‰“å¼€è¾“å‡ºæ–‡ä»¶
    fout = open(OUT_JSONL, "w", encoding="utf-8")

    try:
        for idx, fname in enumerate(files, 1):
            img_path = os.path.join(IMG_DIR, fname)
            print("\n[{:>3}/{}] è¯†åˆ«æ–‡ä»¶ï¼š{}".format(idx, len(files), fname))

            texts, concat = ocr_one_image(ocr, img_path)

            # æ§åˆ¶å°æ‰“å°è¯¦ç»†ç»“æœ
            if not texts:
                print("  âš ï¸ æ²¡æœ‰è¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬")
            else:
                for i, t in enumerate(texts, 1):
                    print("  [{}] '{}' (score={:.3f})".format(
                        i, t["text"], t["score"]
                    ))
                print("  ğŸ‘‰ æ‹¼æ¥é«˜ç½®ä¿¡åº¦æ–‡æœ¬ï¼š", repr(concat))

            # å†™ä¸€è¡Œ JSON åˆ° jsonl æ–‡ä»¶
            record = {
                "file": fname,
                "texts": texts,
                "concat": concat
            }
            fout.write(json.dumps(record, ensure_ascii=False) + "\n")
            fout.flush()

        print("\nâœ… å…¨éƒ¨å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°ï¼š")
        print("   ", OUT_JSONL)

    finally:
        fout.close()


if __name__ == "__main__":
    main()
